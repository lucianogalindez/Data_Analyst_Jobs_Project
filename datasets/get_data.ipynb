{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# pip install python-dotenv\n",
    "# pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'Data Analyst'\n",
    "search_location = 'United States'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "params = {\n",
    "    #\"3b49bf2759555c8a50f74b4cca39c5454f13d6f55a008506210b3b62127531a2\"\n",
    "    #\"8f52e0119de9d3e2a8b7e16b0e32af942736e061a09b3404fbe10dbe95323951\"\n",
    "    \"api_key\": os.getenv('API_KEY2'),\n",
    "    \"device\": \"desktop\",\n",
    "    \"engine\": \"google_jobs\",\n",
    "    \"google_domain\": \"google.com\",\n",
    "    \"q\": search_term,\n",
    "    \"hl\": \"en\",\n",
    "    \"gl\": \"us\",\n",
    "    \"location\": search_location,\n",
    "    \"chips\": \"date_posted:today\",\n",
    "    \"start\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the first version of the collecting file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n",
      "10\n",
      "https://serpapi.com/search\n",
      "20\n",
      "https://serpapi.com/search\n",
      "30\n",
      "https://serpapi.com/search\n",
      "40\n",
      "https://serpapi.com/search\n",
      "50\n",
      "https://serpapi.com/search\n",
      "60\n",
      "https://serpapi.com/search\n",
      "70\n",
      "https://serpapi.com/search\n",
      "80\n",
      "https://serpapi.com/search\n",
      "'jobs_results'\n"
     ]
    }
   ],
   "source": [
    "final_data = pd.DataFrame()\n",
    "\n",
    "for _ in range(30):\n",
    "    \n",
    "    try:\n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict()\n",
    "        jobs_df = results['jobs_results']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "    \n",
    "    jobs_df = pd.DataFrame(jobs_df)\n",
    "\n",
    "    jobs_df = pd.concat([pd.DataFrame(jobs_df),\n",
    "        pd.json_normalize(jobs_df['detected_extensions'])],\n",
    "        axis=1).drop('detected_extensions', axis=1)\n",
    "\n",
    "    final_data = pd.concat([final_data, jobs_df], ignore_index=True)\n",
    "\n",
    "    params[\"start\"] = params[\"start\"] + 10\n",
    "\n",
    "    print(params[\"start\"])\n",
    "\n",
    "#final_data.to_csv('data_analyst_jobs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding current date to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['date_time'] = dt.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['date_time'] = pd.to_datetime(final_data['date_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Data to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-cloud-bigquery\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "key_path = os.getenv('ACCOUNT_LOCATION_NOTEBOOK2')\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/bigquery\"]\n",
    ")\n",
    "\n",
    "upload_data = final_data[['title','company_name','via','description','location','thumbnail','job_id','posted_at','schedule_type','salary','work_from_home','date_time']]\n",
    "\n",
    "client = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=credentials.project_id\n",
    ")\n",
    "\n",
    "table_id = 'polar-arbor-371523.data_analyst_search.jobs_list'\n",
    "\n",
    "table = client.get_table(table_id)\n",
    "\n",
    "errors = client.insert_rows_from_dataframe(table, upload_data)\n",
    "\n",
    "if (errors == [[]] or errors == [[], []]):\n",
    "    print('Data Loaded')\n",
    "else:\n",
    "    print(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bd13bc16400e16874b7ce28af58a129343287e94248a182c1f06fbb6b76ef8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
